#kafka

> Apache Kafka - это распределенная и легко масштабируемая система обмена сообщениями с высокой пропускной способностью, которая может в реальном времени обрабатывать любой объем данных.

Kafka является master-slave (ведущий-ведомый) системой.

### Ссылки с материалами
[Основы Kafka](https://www.youtube.com/watch?v=-AZOi3kP9Js)
[Вводный мини курс по Kafka](https://www.youtube.com/watch?v=DvXPKUUl38w&list=PLWCdmr_xDegcuLlhmXdVFyeNzNbVQdwDM&index=2)
[Небольшая статья по Kafka](https://habr.com/ru/companies/slurm/articles/535374/)

### Из чего состоит Kafka
Минимальный верхне-уровневый набор:
- Broker
- Zookeeper
- Consumer
- Producer

#### Kafka broker (Kafka server/Kafka node)
>  Broker - это экземпляр kafka сервера.
>  Другими словами - серверное ПО, в которое можно записать/получить данные. При этом он эти данные аккумулирует и правильно сохраняет.

Задачи, решаемые Kafka broker:
- Прием сообщений
- Хранение сообщений
- Выдача сообщений

#### Kafka cluster
> это совокупность нескольких Kafka брокеров.

Задачи, решаемые Kafka кластером:
- Масштабирование
- Репликация

#### Zookeeper
> Zookeeper - это распределенное хранилище ключей и их значений. В нем хранится различная конфигурация, которую можно менять налету (информация о брокере, топиках, портициях, доступах и т.д.).

Zookeeper хранит данные Kafka кластера, а именно:
- Состояние кластера
- Конфигурация
- Адресная книга

#### Kafka message
> в основном это key-value пары.

Состав полей Kafka сообщения:
- **Key** (опционально) - ключ используется для распределения по кластеру.
- **Value** - содержимое сообщения (массив байт).
- **Timestamp** - время сообщения. (если его не указывать - оно проставится по дефолту)
- **Headers** - набор key-value пар с пользовательскими атрибутами сообщения.

#### Topic
> это стрим данных
> Топик существует в рамках всего кластера. Т.е. каждый топик существует в каждом брокере кластера. А вот партиция существует в рамках топика и => может располагаться только на одном брокере.

Если партиция 1 :
В топике выстраивается очередь сообщений по FIFO. Т.е. в каком порядке сообщения пришли от продюсера, в таком же порядке потребитель их и вычитывает.

Если партиций > 1 :
Сообщения вычитываются из топика не в том порядке, в котором их передал Producer. Но в рамках каждой отдельной партиции вычитывание упорядочено (по FIFO).

- Если нужно вычитывать сообщения, от конкретного Producer, строго в порядке их поступления, то необходимо **записывать** все эти **сообщения только в одну конкретную партицию**.
  А т.к. в рамках партиции вычитывание упорядочено, то Consumer вычитает их по FIFO.
- При вычитывании сообщений из топика - они не удаляются. Что позволяет сделать широковещательный режим - когда одни и те же сообщения могут читать несколько потребителей.

#### Partitions
> Partitions (от слова part) - т.е. часть топика.

- Партиция существует в рамках топика.
- Партиции имеют порядковый номер в рамках топика, начиная с нуля.
- Партиция делится на сегменты

#### Разнесение топиков/партиций по кластеру брокеров (балансировка)
> Kafka осуществляет автоматическую балансировку кластера по принципу - должно быть одинаковое кол-во партиций на каждом брокере, не учитывая при этом из какого они топика.

По этому возможна следующая несбалансированность по топикам (что большинство партиций из одного топика могут попасть на одного брокера):
![[Pasted image 20240313174155.png|600]]
Данная проблема решается путем ручного конфигурирования, где можно указать - какие партиции на каких брокерах должны лежать.


#### Replications
> Параметр replication-factor (> 1) устанавливает создаваемое количество копий каждой партиции. 

Реплики одной партиции не могу находится на одном брокере.
Одна партиция из всех реплик `(в эту совокурность реплик входит и изначальная партиция, на основе которой создавались остальные реплики)` - назначается лидером.
Остальные реплики - ведомые (Follower-реплики).
Ведомые партиции могут отставать по обновлению данных от лидера.

Kafka Controller (один особенный Kafka Broker в кластере) назначает Leader-реплики.
Чтение и запись сообщений осуществляется ТОЛЬКО в лидер партицию (лидер реплику).

##### Надежность хранения данных и отказоустойчивость
> Master slave - гарантия согласованности данных

- Согласованность данных осуществляется путем опрашивания Follower-репликами Leader-реплики для обновления данных. Но данная схема обновления данных <font style="color:red">является не надежной и не отказоустойчивой</font>, т.к. есть временная задержка м/ду обновлениями.
![[Pasted image 20240314220638.png|600]]
<br>
- Вышеуказанная проблема решается путем введения ISR Follower-а. Данные в ISR Follower-а пишутся синхронно из Leader реплики, сразу после записи в Leader реплику данных.
![[Pasted image 20240314221048.png|600]]


#### Consumer / Producer
> Consumer и Producer - это наше приложение(-ия), которое на борту имеет модуль Kafka и с его помощью подключается к брокеру Kafka.
> Consumer и Producer могут быть как разные приложения, так и одно.
> Они не могут удалять сообщения из Kafka.

#### Producer
> У Producer есть функция `send` для отправки сообщений брокеру. 

У функции `send` есть два важны параметра (чем слабее у них уровень - тем производительнее решение):
1. `acks` - гарантия доставки
   - `acks = 0` - Produser не ждет подтверждение доставки сообщения kafka брокеру.
     (самый не надежный режим - сообщения могут теряться)
   - `acks = 1` - Producer ждет подтверждение доставки сообщения только от Leader-реплики.
     (компромиссный вариант в некоторых случаях - могут теряться сообщения, если брокер с Leader-репликой упал до реплицирования сообщения)
   - `acks = -1 (all)`  -  Producer ждет подтверждение доставки сообщения от всех  ISR-реплик, включая Leader.
     (надежный режим - сообщения не теряются)
2. `Delivery semantic support` - семантика доставки

Что происходит под капотом операции `send`:
1. <font style="color:violet">fetch metadata</font> - получение метаданных о Kafka cluster-е.
   <pre>&#9Продюсеру нужно знать из чего состоит Kafka cluster, какие реплики являются лидерами и где они находятся (из нужного ему топика).
   За этой inf-ей Producer идет:
   - в старых версиях сразу в Zookeeper
   - в новых версиях в Kafka broker -> Zookeeper
</pre>
   
   Операция `send` заявлена как асинхронная (т.е. <font style="color:red">НЕ</font> блокирующая), но <font style="color:violet">fetch metadata</font> выполняется синхронно и является **блокирующий операцией**.
   Поэтому, в случае не получения ответа от Zookeeper, операция `send` может зависнуть на время timeout (по дефолту 60 сек).<br>
   Команда по обращению к внешней системе (Zookeeper) является тяжелой операцией. Поэтому <font style="color:red">не нужно</font> для отправки каждого сообщения создавать нового продюсера.
   <font style="color:green">Необходимо</font> создать одного продюсера, он загрузит метаданные и будет с ними работать (он их кэширует, а после обновляет).
1. <font style="color:violet">serialize message</font> - сериализация сообщений (то есть преобразование их в поток байтов). (<font style="color:red">?</font> `автор в видосе по-моему путает понятия сериализации и десериализации`)
   У Produser-а указывается сериализатор через параметры:
   - `key.serializer` 
   - `value.serializer` 
1. <font style="color:violet">define partition</font> - выбор партиции, в которую пойдет сообщение.
   Есть три стратегии выбора партиции:
   - `explicit partition` - выбор конкретной партиции (например, partition № 0)
   - `round-robin` - выбор партиции возлагается на kafka broker-а. В этом случае сообщения пишутся по очереди (по кругу) в каждую партицию топика.
   - `key-defined` - партиция определяется по ключу сообщения.
     - `key`в сообщении используется для распределения по кластеру. Но по сути он используется для вычисления конкретной партиции в топике, а т.к. топик существует в камках всего кластера => осуществляется и распределение по кластеру.
     - Гарантируется, что если отправляется сообщения с одним и тем же `key` - они будут попадать в одну и ту же партицию.
     - Технически это реализуется путем вычисления остатока от деления хеш-функции ключа на кол-во партиций в топике  (`key_hash % n`).
1. <font style="color:violet">compress message</font> - сжимаются данные сообщения.
2. <font style="color:violet">accumulate batch</font> - сообщения отправляются не по одному, а собираются в пакет сообщений для повышения производительности.
   
   <font style="color:red">Обычно</font> (но не обязательно), каждый отдельный `batch` формируется в рамках отдельной партиции топика.
   
   Есть две настройки, определяющих когда пора отправить сообщения в kafka broker:
   - `batch.size` (по умолчанию = `16 КБ`) - как только набирается сообщений на этот размер - они отправляются.
   - `linger.ms` - отправление сообщений осуществляется по истечению timeout-а. На случай, если долго не может накопиться сообщений на установленный `batch.size`.

   Есть еще одно условие отправки сообщений в kafka broker, когда еще не превышен ни `batch.size`, ни `linger.ms`. Если для одного брокера есть несколько `batch-ей` и их совокупный размер превышает `batch.size` - то все эти сообщения отправляются в kafka broker.
![[Pasted image 20240315010746.png]]

#### Consumer
Consumer читает сообщения сразу из всех лидер партиций. Но это может быть долго и не эффективно. По этому можно объединить потребителей в Consumer Group и каждому потребителю из группы можно назначить определенную партицию, из которой он будет читать сообщения.

##### Kafka Consumer Offset
В Kafka есть системный топик <font style="color:red">_consumer_offsets</font>. В этот топик комитится номер оффсета сообщения партиции, которое последним было обработан Consumer или Consumer Group. 

#### Структура хранения сообщений в файловой системе Kafka брокера
1.  В папке ./logs хранятся папки партиций
   ![[Pasted image 20240112213957.png | 400]]
   Имя папки партиции формируется : <font style="color:red">topicName</font>-<font style="color:green">partitionNumber</font> (<font style="color:red">А</font>-<font style="color:green">0</font>)
2. Внутри папки партиции хранятся уже файлы с данными
   ![[Pasted image 20240112214909.png | 400]]
   - file<font style="color:green">.log</font> - хранятся сообщения
     - Offset - номер сообщения в партиции
     - Position - смещение в этом файле в байтах до конкретного сообщения
   - file<font style="color:green">.index</font> - маппинг Offset на Position
     ![[Pasted image 20240112215340.png | 200]]
     (сообщение с индексом <font style="color:violet">1</font> начинается с <font style="color:violet">67</font> байта в файле)
   - file<font style="color:green">.timeindex</font> - маппинг Timestamp на Offset
3. Партиция делится на сегменты (**Segments**). У file<font style="color:green">.log</font> в партиции есть лимит по размеру (по умолчанию это 1 ГБ). Как только лог файл достигает максимального размера - создается новый сегмент (новые экземпляры всех файлов партиции).
   ![[Pasted image 20240112220042.png | 400]]
   **Segments**
   - активным является самый последний сегмент. Все предыдущие сегменты замораживаются.
   - Имена файлов сегмента формируются на основе **offset** первого записанного сообщения в сегмент.
   - У сегмента тоже есть **timestamp** = максимальному **timestamp** сообщения, находящегося в этом сегменте (и это не обязательно самое последнее сообщение).

### Удаление сообщений из Kafka
> Вручную сообщения удалить нельзя.
> В Kafka поддерживается только автоматическое удаление данных по TTL (time to live)

Минимальная удаляемая единица - сегмент партиций.
Segment timestamp <strong>expired</strong> -> <font style="color:red">to delete</font>
<font style="color:red">ВАЖНО</font>: чтобы автоматический механизм удаления работал корректно, изначально <strong>должен корректно записываться timestamp сообщений в kafka</strong>. Т.к. timestamp сегмента напрямую зависит от timestamp сообщений.

### Когда пригодится kafka
- В качестве инструмента (который разворачивается отдельным приложением) для обмена сообщениями. Особенно если нужно чтобы одинаковые сообщения читали разные приложения.
- Потоковая передача данных.
- Ведение журнала. Kafka все сохраняет в строго организованной структуре.

### Брокер сообщений
> - это архитектурный паттерн в распределённых системах, где элементы системы общаются через посредника. Брокер упрощает работу веб-сервисов, отвечая за пересылку сообщений и все связанные задачи.

В работе брокера сообщений участвуют два ключевых элемента: producer (создатель сообщений) и consumer (получатель/подписчик). Один элемент создает сообщения и отправляет их другому элементу-получателю. В процессе отправки брокер обеспечивает промежуточный этап, сохраняя сообщения от продюсера в определенной папке файловой системы.

#### Когда используются брокеры сообщений
- Отложенное выполнение действий
- Асинхронный обмен сообщениями м/ду сервисами и обеспечение буферизации
- Нужно ускорить обработку сформированных сообщений путем добавления дополнительных подписчиков
- Сгладить пиковые нагрузки, т.к. выполнение задачи и добавление ее в очередь сообщений - имеют разный вес. А далее в брокере сообщений все выполнится в асинхроне.

### Конфигурация Kafka
- bootstrap.servers - это адрес, на котором поднимается kafka.
  По дефолту это `localhost:9092`